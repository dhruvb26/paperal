{
  "sections": [
    {
      "title": "Procedure for the LLM Dataset Inference",
      "content": "We describe the procedure for LLM dataset inference in four stages (see also visualization in Figure 1). Recall the initial example of a book writer who suspects that a portion of their books was trained on. We use this as a running example to describe the four stages of LLM dataset inference.\n\nStage 0: Victim approaches an LLM provider. A victim (author) V approaches an arbiter with a claim of ownership over data (book) that they suspect a model trainer or adversary S utilized. This stage involves the arbiter validating if the claim by V satisfies the assumptions under which dataset inference operates, that is, they provide an IID set of data that they suspect was trained on, and an equivalent dataset that S could not have seen, denoted as the validation set. This can, for instance, happen when authors have multiple drafts of a book chapter, and only one of the drafts makes it to the actual print. In such a case, V claims that S trained on the published version of their book, because f\u03b8 (S) responds differently to the final versus rejected drafts of the book. Both suspect and validation sets are divided into non-overlapping splits (partitions) A and B. We will use Aval, Asus in Stages 1, 2 and Bval, Bsus in Stage 3 to actually perform the ownership assessment.\n\nStage 1: Aggregate Features with MIAs. This step involves aggregating scores from various MIA methods described in the previous Section 2.1. Aval, Asus sets are passed through the LLM under question to obtain their features derived from MIAs. Note that we use an aggregation of all the MIA methods discussed in the previous sections to create a single feature vector. In the next step, we will determine which MIAs are useful for identifying dataset membership for the given distribution.\n\nStage 2: Learn MIA correlations. In this stage, we train a linear regressor to learn the importance of weights for different MIA attacks to use for the final dataset inference procedure. Across each MIA feature value, we first modify the top 5% outliers by changing their values to the mean of the distribution. This step is crucial to prevent issues in Step 3, where the model might learn skewed correlations due to a few outlier samples. We then pass the data through a linear regression model to learn weights for each feature. All \u2018suspect\u2019 samples in Asus are labeled as 0, and all validation samples in Aval are labeled as 1. A regressor is trained to predict the label given the samples, effectively learning the correlation between the features and their membership status.\n\nStage 3: Perform Dataset Inference. We use B splits of the suspect and validation sets, holding out up to 1000 samples in these splits for ownership assessment. Each sample is assigned a membership value using a trained linear classifier. These values are used to perform a statistical t-test to determine if the suspect set was used in training the model. We then report whether the model was trained on the suspect dataset based on the t-test results. For members of the suspect set, their confidence scores are significantly closer to 0 compared to non-members. The null hypothesis (H0) is that the suspect dataset was not used for training. Assume that \u00b5M(Bsus) and \u00b5M(Bval) are the mean membership values of the suspect and validation sets, respectively. Then, H0 and H1 (alternate hypothesis) are:\n\nH0 : \u00b5M(Bsus) \u2265 \u00b5M(Bval); H1 : \u00b5M(Bsus) \u2264 \u00b5M(Bval). (1)",
      "references": []
    },
    {
      "title": "Combining p-values for Dependent Tests",
      "content": "In order to assess the significance of the results, we performed multiple t-tests using 10 different random seeds to obtain various splits of examples between A and B sets. Since the subsets had overlapping examples, the statistical tests are dependent [Vovk and Wang, 2020], and p-values must be aggregated accordingly [Brown, 1975, Kost and McDermott, 2002, Meng, 1994, R\u00fcschendorf, 1982] . Let p1, p2, . . . , pn denote the p-values obtained from the n t-tests performed with different random seeds. Under the null hypothesis, each p-value is uniformly distributed on the interval [0, 1]. We approximate the combined p-value by:\nh\nh (spec) 0) i=1 Pcombined = 1 \u2014 exp\n8",
      "references": [
        {
          "in_text": "[Vovk and Wang, 2020]",
          "complete_reference": "Vladimir Vovk and Ruodu Wang. Combining p-values via averaging. Biometrika, 107(4):791\u2013808, 2020."
        },
        {
          "in_text": "[Brown, 1975]",
          "complete_reference": "Morton B Brown. 400: A method for combining non-independent, one-sided tests of significance. Biometrics, pages 987\u2013992, 1975."
        },
        {
          "in_text": "[Kost and McDermott, 2002]",
          "complete_reference": "James T Kost and Michael P McDermott. Combining dependent p-values. Statistics & Probability Letters, 60(2):183\u2013190, 2002."
        },
        {
          "in_text": "Meng, 1994",
          "complete_reference": "Xiao-Li Meng. Posterior predictive p-values. The annals of statistics, 22(3):1142\u20131160, 1994."
        },
        {
          "in_text": "R\u00fcschendorf, 1982",
          "complete_reference": "Ludger R\u00fcschendorf. Random variables with maximum sums. Advances in Applied Probability, 14(3):623\u2013632, 1982."
        }
      ]
    }
  ]
}