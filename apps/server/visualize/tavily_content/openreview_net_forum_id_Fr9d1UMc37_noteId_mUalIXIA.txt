LLM Dataset Inference: Did you train on my dataset? | OpenReviewToggle navigationOpenReview.netLoginOpen Peer Review. Open Publishing. Open Access. Open Discussion. Open Recommendations. Open Directory. Open API. Open Source.×LLM Dataset Inference: Did you train on my dataset?Pratyush Maini, Hengrui Jia, Nicolas Papernot, Adam Dziedzic  Published: 25 Sept 2024, Last Modified: 01 Jan 2025NeurIPS 2024 posterEveryoneRevisionsBibTeXCC BY 4.0Keywords: LLM, dataset inference, membership inference, copyrightTL;DR: We detect if a given text was used to train an LLM using the dataset inference technique.Abstract: The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet. Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs). 
We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model). This distribution shift makes membership inference appear successful. 
However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time).
Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions.
Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models. This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph.
While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset. Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values $< 0.1$, without any false positives.Supplementary Material:  zipPrimary Area: Safety in machine learningSubmission Number: 1328LoadingAbout OpenReviewHosting a VenueAll VenuesContactFeedbackSponsorsJoin the TeamFrequently Asked QuestionsTerms of UsePrivacy PolicyAbout OpenReviewHosting a VenueAll VenuesSponsorsJoin the TeamFrequently Asked QuestionsContactFeedbackTerms of UsePrivacy PolicyOpenReview is a long-term project to advance science through improved peer review, with legal nonprofit status through Code for Science & Society. We gratefully acknowledge the support of the OpenReview Sponsors. © 2025 OpenReview×Send FeedbackEnter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository:Report an issueSelect a topic or type what you need help withCancelSend×BibTeX RecordClick anywhere on the box above to highlight complete recordDone