["Preprint", "However, most existing forms of contamination are benign. In the benign contamination setting we consider, pretraining datasets become contaminated when test sets accidentally slip through filtering mechanisms Brown et al. (2020a). In this case, we have a reasonable expectation that the invariance in proposition 1 will be violated and log p\u03b8(seq(X)) \u226b log p\u03b8(seq(X\u03c0)) as the language model \u03b8 is explicitly trained to maximize the log-likelihood over its training data, including seq(X). The vio- lation of exchangability allows us to reliably detect test set contamination, and the existing literature on memorization (Carlini et al., 2021) suggests that many models may verbatim memorize the order of examples in a benchmark dataset. We now focus on building tests that can reliably identify this form of memorization.", "3 METHODS", "The core idea of our statistical test is to compare the log probability of the dataset under its original ordering to the log probability under random permutations. We begin by describing the basic version of this idea, which directly implements a permutation test on the log probabilities. We then identify some drawbacks of this approach and describe a sharded test which improves the statistical power and computational efficiency of the test.", "3.1 A PERMUTATION TEST FOR CONTAMINATION", "Under the null hypothesis, the likelihood under the model of any permutation of the dataset X\u03c0 has the same distribution, and thus the rank of log p\u03b8(seq(X)) among any set of randomly permuted probabilities {log p\u03b8(seq(X\u03c01)) . . . log p\u03b8(seq(X\u03c0n ))} will be a uniform random variable over [n + 1] (Lehmann & Romano, 2005, Theorem 15.2.2).", "This can be used directly to construct a permutation test. Consider the proportion of permuted copies of X with lower log-likeihood than the canonical ordering under the model,", "p := E[1{log p\u03b8(seq(X)) < log p\u03b8(seq(X\u03c0))}].", "The distribution of p will be uniform under H0, and we can test for contamination at a significance level \u03b1 by rejecting H0 when p < \u03b1. In practice, computing this expectation over all \u03c0 is intractable, and we replace this with a Monte Carlo estimate and the appropriate finite-sample correction (Phip- son & Smyth, 2010), which gives", "\u02c6p := i=1 1{log p\u03b8(seq(X)) < log p\u03b8(seq(X\u03c0m ))} + 1 m + 1", ".", "This test is simple and straightforward to implement, and the validity of this test when rejecting at \u02c6p \u2264 \u03b1 is clear from standard results on permutation testing (Lehmann & Romano, 2005; Phipson & Smyth, 2010). However, this test suffers from a major drawback in its Monte Carlo implementation \u2013 the runtime of the test in terms of the number of log probability computations is O(m|X|) for a sequence of length |X| and the p-value can never be below 1/(m + 1). For hypothesis tests that aim to reject at very low p-values (or with substantial multiple hypothesis testing corrections), this poses a tradeoff between statistical power and computational requirements.", "3.2 A SHARDED LIKELIHOOD COMPARISON TEST FOR CONTAMINATION", "What are some drawbacks of the naive permutation test? It has an undesirable tradeoff between statistical power and computational requirements for small \u03b1, and also requires that the model assign higher likelihood to the canonical ordering X than nearly all shuffled orderings of X\u03c0. This latter condition can also be a serious problem, as the model may have biases the prefer certain orderings (e.g. ones that place duplicate examples next to each other) regardless of the order seen during training.", "A more likely assumption would be that the log-probability under the canonical ordering X is higher than the average log probability under a random permutation. That is, instead of relying on the quantile E[1{log p\u03b8(seq(X)) < log p\u03b8(seq(X\u03c0))}], can we instead perform multiple log probability comparisons of the form log p\u03b8(seq(X)) < E[log p\u03b8(seq(X\u03c0))]?", "4"]