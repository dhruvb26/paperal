["Preprint\nA\nOUTLOOK\nA.1\nSELF-IMPROVEMENT MECHANISMS\nOne limitation of the MetaGPT version in the main text of this paper is that each software project is\nexecuted independently. However, through active teamwork, a software development team should\nlearn from the experience gained by developing each project, thus becoming more compatible and\nsuccessful over time.\nThis is somewhat related to the idea of recursive self-improvement, first informally proposed in\n1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b;\nSchmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential\nself-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experi-\nence in the real world, and meta-learn better learning algorithms from experiences of learning, and\nmeta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without\nany limitations except those of computability and physics.\nMore recent, somewhat related work leverages the reasoning ability of Large Language Models\n(LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream\ntasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of\n2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or\nprompts for another pre-trained neural network whose answers may help the first network to learn\nnew tasks more quickly.\nIn our present work, we also explore a self-referential mechanism that recursively modifies the con-\nstraint prompts of agents based on information they observe during software development. Our\ninitial implementation works as follows. Prior to each project, every agent in the software company\nreviews previous feedback and makes necessary adjustments to their constraint prompts. This en-\nables them to continuously learn from past project experiences and enhance the overall multi-agent\nsystem by improving each individual in the company. We first establish a handover feedback action\nfor each agent. This action is responsible for critically summarizing the information received dur-\ning the development of previous projects and integrating this information in an updated constraint\nprompt. The summarized information is stored in long-term memory such that it can be inherited\nby future constraint prompt updates. When initiating a new project, each agent starts with a react\naction. Each agent evaluates the received feedback and summarizes how they can improve in a\nconstraint prompt.\nOne current limitation is that these summary-based optimizations only modify constraints in the\nspecialization of roles (Sec. 3.1) rather than structured communication interfaces in communication\nprotocols (Sec. 3.2). Future advancements are yet to be explored.\nA.2\nMULTI-AGENT ECONOMIES\nIn real-world teamwork, the interaction processes are often not hardcoded. For example, in a soft-\nware company, the collaboration SOP may change dynamically.\nOne implementation of such self-organization is discussed in the paper on a \u201cNatural Language-\nBased Society of Mind\u201d (NLSOM) (Zhuge et al., 2023), which introduced the idea of an \u201cEconomy\nof Minds\u201d (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other\nagents. Instead of using standard RL techniques to optimize the total reward of the system through\nmodifications of neural network parameters, EOMs use the principles of supply and demand in free\nmarkets to assign credit (money) to those agents that contribute to economic success (reward).\nThe recent agent-based platform of DeepWisdom (AgentStore4) is compatible with the credit as-\nsignment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding\ncosts. A convenient API is provided so that human users or agents in the platform can easily pur-\nchase services from other agents to accomplish their services. Figure 6 displays the User Interface\n(UI) of AgentStore, where various agents with different skills are showcased. Besides, individual\ndevelopers can participate in building new agents and enable collaborative development within the\ncommunity. Specifically, AgentStore allows users to subscribe to agents according to their demands\n4http://beta.deepwisdom.ai\n15\n"]