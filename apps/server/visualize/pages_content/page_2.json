["sequences or their clusters naturally occur. For instance, consider the Harry Potter series written by J.K.\nRowling. Dataset inference tests whether a \u2018dataset\u2019 or a collection of paragraphs from her books was\nused for training a language model, rather than testing the membership of individual sentences alone. We\nalso outline the specific framework required to operationalize dataset inference, including the necessary\nassumptions for the same.\nWe carry out our analysis of dataset inference using LLMs with known training and validation data.\nSpecifically, we leverage the Pythia suite of models Biderman et al. [2023] trained on the Pile dataset Gao\net al. [2020] (Section 5). This controlled experimental setup allows us to precisely analyze the model\nbehavior on members and non-members when they occur IID (without any temporal shift) as the training\nand validation splits of PILE are publicly accessible. Across all subsets, dataset inference achieves p-values\nless than 0.1 in distinguishing between training and validation splits. At the same time, our method shows\nno false positives, with our statistical test producing p-values larger than 0.5 in all cases when comparing\ntwo subsets of validation data. To its practical merit, dataset inference requires only 1000 text sequences to\ndetect whether a given suspect dataset was used to train an LLM.\n2\nBackground and Baselines\nMembership Inference\n(MI) [Shokri et al., 2017]. The central question is: Given a trained model and a\nparticular data point, can we determine if the data point was in the model\u2019s training set? Applications of\nMI methods span across detecting contamination in benchmark datasets [Oren et al., 2024, Shi et al., 2024],\nauditing privacy [Steinke et al., 2023], and identifying copyrighted texts within pre-training data [Shafran\net al., 2021]. The field has been studied extensively in the realm of ML models trained via supervised\nlearning on small datasets. The ability of membership inference in the context of large-scale language\nmodels (LLMs) remains an open problem. Recently, new methods [Mattern et al., 2023, Shi et al., 2024]\nhave been proposed to close the gap and we present them in \u00a7 2.1.\nDataset Inference\n[Maini et al., 2021] provides a strong statistical claim that a given model is a\nderivative of its own private training data. The key intuition behind the original method proposed for\nsupervised learning is that classifiers maximize the distance of training examples from the model\u2019s decision\nboundaries, while the test examples are closer to the decision boundaries since they have no impact on the\nmodel weights. Subsequently, dataset inference was extended from supervised learning to the self-supervised\nlearning (SSL) models [Dziedzic et al., 2022] based on the observation that representations of the training\ndata points induce a significantly different distribution than the representation of the test data points. We\nintroduce dataset inference for large language models to detect datasets used for training.\n2.1\nMetrics for LLM Membership Inference\nThis section explores various metrics used to assess Membership Inference Attacks (MIAs) against LLMs.\nWe study MIAs under gray-box access (which assumes access to the model loss, but not to parameters or\ngradients). The adversary aims to learn an attack function Af\u03b8 : X \u2192{0, 1} that takes an input x from\ndistribution X and determines whether x was in the training set Dtrain of the LM f\u03b8 or not. Let us now\ndescribe the MIAs we use in our work.\nThresholding Based.\nThese MIAs leverage loss [Yeom et al., 2018] or perplexity [Carlini et al., 2021] as\nscores and then threshold them to classify samples as members or non-members. Specifically, the decision\nrule for membership is: Af\u03b8(x) = 1[L(f\u03b8, x) < \u03b3], where \u03b3 is a selected pre-defined threshold. However,\nMIAs based solely on perplexity suffer from many false positives, where simple and predictable sequences\nthat never occur in the training set can be labeled as members.\n3\n"]