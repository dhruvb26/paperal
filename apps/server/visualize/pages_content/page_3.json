["Preprint", "Our three contributions suggest that black-box identification of test set contamination is practical and further improvements in the power of the tests may allow us to regularly audit language models in the wild for test set contamination. To encourage the development of new provable guarantees for test set contamination, we release our pretrained models as a benchmark for developing future statistical tests.1.", "2 PROBLEM SETTING", "Our high-level goal is to identify whether the training process of a language model \u03b8 included dataset X. In our setting, the only method we have to study \u03b8 is through a log probability query log p\u03b8(s) for a sequence s (i.e. no access to dataset or parameters). This setting mirrors many common situations with API-based model providers (Brown et al., 2020b; Bai et al., 2022) and matches an increasing trend where the training data is kept secret for \u2018open\u2019 models (Touvron et al., 2023; Li et al., 2019).", "Provably identifying test set contamination can be viewed as a hypothesis test in which the goal is to distinguish between two hypotheses:", "H0: \u03b8 is independent of X", "H1: \u03b8 is dependent on X", "where we treat \u03b8 as a random variable whose randomness arises from a combination of the draw of the pretraining dataset (potentially including X) and we will propose a hypothesis test with the property that it falsely rejects the null hypothesis H0 with probability at most \u03b1.", "False positives under H0 In most cases, we can make use of a property of a dataset known as exchangeability to obtain our false positive guarantee. Nearly all datasets can be expressed as a collection of examples X := {x1 . . . xn} where the ordering of the examples are unimportant, and the probability of any ordering would be equally likely (i.e. p(x1 . . . xn) = p(x\u03c01 . . . x\u03c0n ) for any permutation \u03c0). Notably, this assumption would hold under the standard assumption that the dataset is a collection of i.i.d examples.", "Whenever exchangability of the dataset holds, the log probabilities of the model under H0 must have a useful invariance property,", "Proposition 1. Let seq(X) be a function that takes a dataset X and concatenates the examples to produce a sequence, and let X\u03c0 be a random permutation of the examples of X where \u03c0 is drawn uniformly from the permutation group. For an exchangeable dataset X and under H0,", "log p\u03b8(seq(X)) d= log p\u03b8(seq(X\u03c0)).", "Proof This follows directly from the definitions of exchangability and H0. Since X is ex- changable, seq(X) d= seq(X\u03c0) and by the independence of \u03b8 from X under H0, we know that (\u03b8, seq(X)) d= (\u03b8, seq(X\u03c0)). Thus, the pushforward under log p\u03b8(seq(X)) must have the same invariance property.", "Proposition 1 is the basic building block of our tests. It implies that the log probabilities of X under H0 have the same distribution when shuffled, and this permutation invariance will enable us to directly apply standard results on constructing permutation tests (Lehmann & Romano, 2005).", "Detection rate under H1 The false positive rate guarantee holds with extremely weak assump- tions, but a useful test should also have high power, meaning that it should have a high detection rate under H1. We cannot hope for high detection rate without further assumptions. For instance, an adversary may hide an encrypted copy of X within the parameters of the model (which would induce a clear dependence between the model and X) but it would be nearly impossible for us to detect such a situation even with weight access.", "1https://github.com/tatsu-lab/test_set_contamination", "3"]