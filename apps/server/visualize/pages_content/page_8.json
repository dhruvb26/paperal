["Preprint", "our pre-trained models trained on Wikitext mixtures together with the corresponding canary test sets2.", "In addition to the release, we will maintain a leaderboard of methods that provide (asymptotically valid) p-values, ranking methods by the average log p-value. We hope that the model and bench- mark spurs further development of tests for contamination, and encourage members of the research community to improve on our results for low duplication counts.", "4.2 SHARDING AND PERMUTATION COUNT", "Our test relies on two parameters \u2013 the number of shards in the test, and the number of permutations to sample. Both of these affect the power of the test, and we carefully study the impact of these parameters on our ability to detect test sets by evaluating our pre-trained model on the 6 datasets that contain 1000 examples (BoolQ, HellaSwag, MNLI, NaturalQuestions, TruthfulQA, PIQA). For the number of shards, we explore a range of settings, from 10 shards to 200 shards and for permutations we test a range from 1 to 50 permutations.", "Shard sensitivity Our results in Figure 3a show that there is a sweet spot to the number of shards, around 10-20 shards, where our detection rate for test sets are maximized. Larger numbers of shards perform worse, since each shard involves fewer examples. Shards below 10 do not perform well, as this is likely too few samples to merit the use of an asymptotically valid test like the t-test.", "Average log p-value vs. Examples per Shard o -2 3 $3 a 2-4 8 <6 2 5 10 20 50 100 Examples per Shard 500 200 100 50 20 10 Number of Shards", "Average log p-value vs. Permutations per Shard", "-2.5 \u00ae 3 g 2 -3.0 B35 g < -4.0 6.10 20. #230. 40. 50 Permutations per Shard", "(a) So long as each shard contains enough exam- ples and enough shards are used, the p-value is stable under variations of the number of shards r. We plot the average log p-value of those six of our pre-trained model benchmarks with 1,000 exam- ples, varying the number of examples per shard.", "(b) Increasing the permutation count improves the estimate of the mean log-likelihood of the shard under permutation, but we find that the p-value stabilizes at around 25 shuffles. We plot the aver- age logarithm of the p-value(s) of 6 datasets eval- uated on our pretrained model as a function of per- mutations per shard.", "Figure 3: Impact of varying shard and permutation counts on test performance.", "Permutation count sensitivity We also measure the dependence of our test on the number of permutations per shard in Figure 3b, and find more permutations to generally improve the power of our test. We test permutations of 1, 2, 10, 25, 50 and compute the average log p-value of the 6 datasets evaluated on the pretrained model. In practice we find that there is substantial diminishing returns beyond 25 permutations in the t-test. This stands in stark contrast to the permutation test, where a permutation count of 25 would only allow for a minimum p-value of 0.038.", "4.3 EVALUATING EXISTING MODELS FOR DATASET CONTAMINATION", "We now demonstrate the utility of our procedure in validating test set contamination in multiple publicly available language models: LLaMA2 (Touvron et al. (2023)), Mistral-7B (Mistral (2023)), Pythia-1.4B (Biderman et al. (2023)), and GPT-2 XL (Radford et al. (2018)), on eight public test benchmarks: AI2-Arc (Clark et al. (2018)), BoolQ (Clark et al. (2019)), GSM8K (Cobbe et al.", "2", "8"]