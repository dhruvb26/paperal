["Split A\nSuspect\nFeatures\n(A)\nVal\nFeatures\n(A)\nSplit A\n,\u00a0 0\n,\u00a0 1\nSuspect\nFeatures\n(A)\nVal\nFeatures\n(A)\n, Attack\nStage 1: Aggregate Features with MIAs\n+\nStage 2: Learn Correlations\nStage 3: Perform Dataset Inference\nSplit B\nSplit B\n+Attack\n{0.3, 0.1, ..., 0.2}\n{0.9, 0.2, ..., 0.7}\nT-Test\nTrain Linear Model\nStage 0: Victim approaches with a Suspect set\nClaim:\nLLM trained on Suspect set\nAssumption:\nSuspect set and Val set are IID\nVal set is private to the victim\u00a0\nSplit A\nSplit B\nSuspect Set\n...\nSplit A\nSplit B\n...\nVal Set\nFigure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim\u2019s data\nconsists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was\npotentially used to train the LLM. The validation set is private to the victim, such as unpublished data\n(e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are\ndivided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The\nA splits from suspect and validation sets are passed through the LLM to obtain their features, which\nare scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and\ntheir membership status). We train a linear model using the extracted features to assign label 0 (denoting\npotential members of the LLM) to the suspect and label 1 (representing non-members) to the validation\nfeatures. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of\nthe suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then\nobtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical\nT-Test on the obtained scores. For the suspect data points that are members, their confidence scores are\nsignificantly closer to 0 than for the non-members.\nMaini et al. [2021] presented an impossibility result suggesting that as the size of the training set increases,\nthe success of membership inference degrades to random chance. Is testing the membership of individual\nsentences for LLMs trained for a single epoch on trillions of tokens of text data feasible? In our work, we\nfirst demonstrate that previous claims of successful membership inference for individual text sequences in\nLLMs [Mattern et al., 2023, Shi et al., 2024] are overly optimistic (Section 4). Our evaluation of the MIA\nmethods for LLMs reveals a crucial confounder: they detect (temporal) distribution shifts rather than the\nmembership of data points (as also concurrently observed by [Duan et al., 2024]). Specifically, we find that\nthese MIAs infer whether an LLM was trained on a concept rather than an individual sentence. Even when\nthe outputs of such MIAs (weakly) correlate with actual sentence membership, we find that they remain\nvery brittle across sentences from different data distributions, and no single MIA succeeds across all. Based\non our experiments, we conclude the discussion of MIAs with guidelines for future researchers to conduct\nrobust experiments, highlighting the importance of using IID splits (between members and non-members),\nconsidering various data distributions, and evaluating false positives to mitigate confounding factors.\nIf membership inference attacks are so brittle, do content writers and private individuals have no recourse\nto claim that LLM providers unfairly trained on their data? As an alternative to membership inference, we\nadvocate for a shift in focus towards dataset inference [Maini et al., 2021], which is a statistically grounded\nmethod to detect if a given dataset was in the training set of a model. We propose a new dataset inference\nmethod for LLMs that aims at detecting sets of text sequences by specific authors, thereby offering a more\nviable approach to dataset attribution than membership inference. Our method is presented in Figure 1.\nThe motivation behind dataset inference stems from the observation that in the rapidly evolving discourse\non copyright, individual data points have much less agency than sets of data points attributed to a particular\ncreator; and the fact that more often than not, cases of unfair use emerge in scenarios when multiple such\n2\n"]